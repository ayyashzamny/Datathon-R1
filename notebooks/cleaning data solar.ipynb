{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af4e93e3-cdcb-4c7c-b416-54ce963e06f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "  LOCATION            DATE_TIME  SENSOR_ID  DC_POWER  AC_POWER  DAILY_YIELD  \\\n",
      "0        A  2020-05-15 00:00:00   sensor 1       0.0       0.0          0.0   \n",
      "1        A  2020-05-15 00:00:00   sensor 2       0.0       0.0          0.0   \n",
      "2        A  2020-05-15 00:00:00   sensor 3       0.0       0.0          0.0   \n",
      "3        A  2020-05-15 00:00:00   sensor 5       0.0       0.0          0.0   \n",
      "4        A  2020-05-15 00:00:00  sensor 12       0.0       0.0          0.0   \n",
      "\n",
      "   TOTAL_YIELD  \n",
      "0    6259559.0  \n",
      "1    6183645.0  \n",
      "2    6987759.0  \n",
      "3    7602960.0  \n",
      "4    7158964.0  \n",
      "\n",
      "Before DateTime Conversion:\n",
      "0    2020-05-15 00:00:00\n",
      "1    2020-05-15 00:00:00\n",
      "2    2020-05-15 00:00:00\n",
      "3    2020-05-15 00:00:00\n",
      "4    2020-05-15 00:00:00\n",
      "Name: DATE_TIME, dtype: object\n",
      "\n",
      "Missing Values Before Handling:\n",
      "LOCATION       0\n",
      "DATE_TIME      0\n",
      "SENSOR_ID      0\n",
      "DC_POWER       0\n",
      "AC_POWER       0\n",
      "DAILY_YIELD    0\n",
      "TOTAL_YIELD    0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values After Handling:\n",
      "LOCATION       0\n",
      "DATE_TIME      0\n",
      "SENSOR_ID      0\n",
      "DC_POWER       0\n",
      "AC_POWER       0\n",
      "DAILY_YIELD    0\n",
      "TOTAL_YIELD    0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Rows Before Removing:\n",
      "0\n",
      "\n",
      "Duplicate Rows After Removing:\n",
      "0\n",
      "\n",
      "Negative Values Check Before Handling:\n",
      "DC_POWER       0\n",
      "AC_POWER       0\n",
      "DAILY_YIELD    0\n",
      "dtype: int64\n",
      "\n",
      "Negative Values Check After Handling:\n",
      "DC_POWER       0\n",
      "AC_POWER       0\n",
      "DAILY_YIELD    0\n",
      "dtype: int64\n",
      "\n",
      "Data Types Before Conversion:\n",
      "LOCATION        object\n",
      "DATE_TIME       object\n",
      "SENSOR_ID       object\n",
      "DC_POWER       float64\n",
      "AC_POWER       float64\n",
      "DAILY_YIELD    float64\n",
      "TOTAL_YIELD    float64\n",
      "dtype: object\n",
      "\n",
      "Data Types After Conversion:\n",
      "LOCATION        object\n",
      "DATE_TIME       object\n",
      "SENSOR_ID       object\n",
      "DC_POWER       float64\n",
      "AC_POWER       float64\n",
      "DAILY_YIELD    float64\n",
      "TOTAL_YIELD    float64\n",
      "dtype: object\n",
      "\n",
      "Cleaned Data:\n",
      "  LOCATION            DATE_TIME  SENSOR_ID  DC_POWER  AC_POWER  DAILY_YIELD  \\\n",
      "0        A  2020-05-15 00:00:00   sensor 1       0.0       0.0          0.0   \n",
      "1        A  2020-05-15 00:00:00   sensor 2       0.0       0.0          0.0   \n",
      "2        A  2020-05-15 00:00:00   sensor 3       0.0       0.0          0.0   \n",
      "3        A  2020-05-15 00:00:00   sensor 5       0.0       0.0          0.0   \n",
      "4        A  2020-05-15 00:00:00  sensor 12       0.0       0.0          0.0   \n",
      "\n",
      "   TOTAL_YIELD  \n",
      "0    6259559.0  \n",
      "1    6183645.0  \n",
      "2    6987759.0  \n",
      "3    7602960.0  \n",
      "4    7158964.0  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset from CSV (you can replace the file path with your actual file path)\n",
    "data = pd.read_csv('dated_solar_data.csv')\n",
    "\n",
    "# Show the first few rows of the dataset to understand its structure\n",
    "print(\"Original Data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Data Preparation\n",
    "\n",
    "# 1. Skipping DateTime conversion since you requested to remove this step.\n",
    "# If you want to work with 'DATE_TIME' in its original format, you can print the column before and after\n",
    "print(\"\\nBefore DateTime Conversion:\")\n",
    "print(data['DATE_TIME'].head())  # Print 'DATE_TIME' column before conversion\n",
    "\n",
    "# 2. Check for missing values\n",
    "print(\"\\nMissing Values Before Handling:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 3. Handle missing values (example: filling missing values with the median of the column)\n",
    "data['DC_POWER'] = data['DC_POWER'].fillna(data['DC_POWER'].median())\n",
    "data['AC_POWER'] = data['AC_POWER'].fillna(data['AC_POWER'].median())\n",
    "data['DAILY_YIELD'] = data['DAILY_YIELD'].fillna(data['DAILY_YIELD'].median())\n",
    "data['TOTAL_YIELD'] = data['TOTAL_YIELD'].fillna(data['TOTAL_YIELD'].median())\n",
    "\n",
    "print(\"\\nMissing Values After Handling:\")\n",
    "print(data.isnull().sum())  # Check if missing values were handled\n",
    "\n",
    "# 4. Check for duplicates\n",
    "print(\"\\nDuplicate Rows Before Removing:\")\n",
    "print(data.duplicated().sum())  # This will show how many duplicate rows exist\n",
    "\n",
    "# 5. Remove duplicates if found\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "print(\"\\nDuplicate Rows After Removing:\")\n",
    "print(data.duplicated().sum())  # Check if duplicates were removed\n",
    "\n",
    "# 6. Check for any obvious data inconsistencies or outliers\n",
    "print(\"\\nNegative Values Check Before Handling:\")\n",
    "print(data[['DC_POWER', 'AC_POWER', 'DAILY_YIELD']].lt(0).sum())\n",
    "\n",
    "# Handle negative values by replacing them with 0 or a valid value\n",
    "data[['DC_POWER', 'AC_POWER', 'DAILY_YIELD']] = data[['DC_POWER', 'AC_POWER', 'DAILY_YIELD']].apply(lambda x: x.clip(lower=0))\n",
    "\n",
    "print(\"\\nNegative Values Check After Handling:\")\n",
    "print(data[['DC_POWER', 'AC_POWER', 'DAILY_YIELD']].lt(0).sum())  # Check if negative values were handled\n",
    "\n",
    "# 7. Convert numerical columns to appropriate types (e.g., float)\n",
    "print(\"\\nData Types Before Conversion:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "data['DC_POWER'] = data['DC_POWER'].astype(float)\n",
    "data['AC_POWER'] = data['AC_POWER'].astype(float)\n",
    "data['DAILY_YIELD'] = data['DAILY_YIELD'].astype(float)\n",
    "data['TOTAL_YIELD'] = data['TOTAL_YIELD'].astype(float)\n",
    "\n",
    "print(\"\\nData Types After Conversion:\")\n",
    "print(data.dtypes)  # Check if the types were changed correctly\n",
    "\n",
    "# Final Data Review\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Save the cleaned data to a new CSV file (optional)\n",
    "data.to_csv('cleaned_data_solar1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6205292-e362-4cbc-891a-6f8a83090f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
